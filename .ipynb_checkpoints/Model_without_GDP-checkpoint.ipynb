{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Latitutde</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walhalla</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>3407</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Trains</td>\n",
       "      <td>0</td>\n",
       "      <td>-97.91</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metaline Falls</td>\n",
       "      <td>Washington</td>\n",
       "      <td>3025</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Rail Containers Full</td>\n",
       "      <td>0</td>\n",
       "      <td>-117.30</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oroville</td>\n",
       "      <td>Washington</td>\n",
       "      <td>3019</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Rail Containers Empty</td>\n",
       "      <td>0</td>\n",
       "      <td>-119.46</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanceboro</td>\n",
       "      <td>Maine</td>\n",
       "      <td>105</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Bus Passengers</td>\n",
       "      <td>0</td>\n",
       "      <td>-67.43</td>\n",
       "      <td>45.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noonan</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>3420</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Truck Containers Empty</td>\n",
       "      <td>512</td>\n",
       "      <td>-103.00</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Port Name         State  Port Code            Border       Date  \\\n",
       "0        Walhalla  North Dakota       3407  US-Canada Border 2012-12-01   \n",
       "1  Metaline Falls    Washington       3025  US-Canada Border 2012-12-01   \n",
       "2        Oroville    Washington       3019  US-Canada Border 2012-12-01   \n",
       "3       Vanceboro         Maine        105  US-Canada Border 2012-12-01   \n",
       "4          Noonan  North Dakota       3420  US-Canada Border 2012-12-01   \n",
       "\n",
       "                  Measure  Value  Latitutde  Longitude  \n",
       "0                  Trains      0     -97.91      49.00  \n",
       "1    Rail Containers Full      0    -117.30      49.00  \n",
       "2   Rail Containers Empty      0    -119.46      49.00  \n",
       "3          Bus Passengers      0     -67.43      45.57  \n",
       "4  Truck Containers Empty    512    -103.00      49.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/Borderdata_train.csv\", parse_dates=[\"Date\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Latitutde</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Month_year</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walhalla</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>3407</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Trains</td>\n",
       "      <td>0</td>\n",
       "      <td>-97.91</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metaline Falls</td>\n",
       "      <td>Washington</td>\n",
       "      <td>3025</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Rail Containers Full</td>\n",
       "      <td>0</td>\n",
       "      <td>-117.30</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oroville</td>\n",
       "      <td>Washington</td>\n",
       "      <td>3019</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Rail Containers Empty</td>\n",
       "      <td>0</td>\n",
       "      <td>-119.46</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanceboro</td>\n",
       "      <td>Maine</td>\n",
       "      <td>105</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Bus Passengers</td>\n",
       "      <td>0</td>\n",
       "      <td>-67.43</td>\n",
       "      <td>45.57</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noonan</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>3420</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Truck Containers Empty</td>\n",
       "      <td>512</td>\n",
       "      <td>-103.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2012-12</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Port Name         State  Port Code            Border       Date  \\\n",
       "0        Walhalla  North Dakota       3407  US-Canada Border 2012-12-01   \n",
       "1  Metaline Falls    Washington       3025  US-Canada Border 2012-12-01   \n",
       "2        Oroville    Washington       3019  US-Canada Border 2012-12-01   \n",
       "3       Vanceboro         Maine        105  US-Canada Border 2012-12-01   \n",
       "4          Noonan  North Dakota       3420  US-Canada Border 2012-12-01   \n",
       "\n",
       "                  Measure  Value  Latitutde  Longitude Month_year  Year  Month  \n",
       "0                  Trains      0     -97.91      49.00    2012-12  2012     12  \n",
       "1    Rail Containers Full      0    -117.30      49.00    2012-12  2012     12  \n",
       "2   Rail Containers Empty      0    -119.46      49.00    2012-12  2012     12  \n",
       "3          Bus Passengers      0     -67.43      45.57    2012-12  2012     12  \n",
       "4  Truck Containers Empty    512    -103.00      49.00    2012-12  2012     12  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Month_year'] = train['Date'].dt.to_period('M')\n",
    "train['Year'] = train[\"Date\"].dt.year\n",
    "train['Month'] = train[\"Date\"].dt.month\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Latitutde</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calexico East</td>\n",
       "      <td>California</td>\n",
       "      <td>2507</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>34447</td>\n",
       "      <td>-115.48433</td>\n",
       "      <td>32.67524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Van Buren</td>\n",
       "      <td>Maine</td>\n",
       "      <td>108</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Rail Containers Full</td>\n",
       "      <td>428</td>\n",
       "      <td>-67.94271</td>\n",
       "      <td>47.16207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otay Mesa</td>\n",
       "      <td>California</td>\n",
       "      <td>2506</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>81217</td>\n",
       "      <td>-117.05333</td>\n",
       "      <td>32.57333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nogales</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2604</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trains</td>\n",
       "      <td>62</td>\n",
       "      <td>-110.93361</td>\n",
       "      <td>31.34028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trout River</td>\n",
       "      <td>New York</td>\n",
       "      <td>715</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>16377</td>\n",
       "      <td>-73.44253</td>\n",
       "      <td>44.99001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Port Name       State  Port Code            Border       Date  \\\n",
       "0  Calexico East  California       2507  US-Mexico Border 2019-03-01   \n",
       "1      Van Buren       Maine        108  US-Canada Border 2019-03-01   \n",
       "2      Otay Mesa  California       2506  US-Mexico Border 2019-03-01   \n",
       "3        Nogales     Arizona       2604  US-Mexico Border 2019-03-01   \n",
       "4    Trout River    New York        715  US-Canada Border 2019-03-01   \n",
       "\n",
       "                       Measure  Value  Latitutde  Longitude  \n",
       "0                       Trucks  34447 -115.48433   32.67524  \n",
       "1         Rail Containers Full    428  -67.94271   47.16207  \n",
       "2                       Trucks  81217 -117.05333   32.57333  \n",
       "3                       Trains     62 -110.93361   31.34028  \n",
       "4  Personal Vehicle Passengers  16377  -73.44253   44.99001  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/Borderdata_test.csv\", parse_dates=[\"Date\"])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "      <th>Latitutde</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Month_year</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calexico East</td>\n",
       "      <td>California</td>\n",
       "      <td>2507</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>34447</td>\n",
       "      <td>-115.48433</td>\n",
       "      <td>32.67524</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Van Buren</td>\n",
       "      <td>Maine</td>\n",
       "      <td>108</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Rail Containers Full</td>\n",
       "      <td>428</td>\n",
       "      <td>-67.94271</td>\n",
       "      <td>47.16207</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otay Mesa</td>\n",
       "      <td>California</td>\n",
       "      <td>2506</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>81217</td>\n",
       "      <td>-117.05333</td>\n",
       "      <td>32.57333</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nogales</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2604</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Trains</td>\n",
       "      <td>62</td>\n",
       "      <td>-110.93361</td>\n",
       "      <td>31.34028</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trout River</td>\n",
       "      <td>New York</td>\n",
       "      <td>715</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>16377</td>\n",
       "      <td>-73.44253</td>\n",
       "      <td>44.99001</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Port Name       State  Port Code            Border       Date  \\\n",
       "0  Calexico East  California       2507  US-Mexico Border 2019-03-01   \n",
       "1      Van Buren       Maine        108  US-Canada Border 2019-03-01   \n",
       "2      Otay Mesa  California       2506  US-Mexico Border 2019-03-01   \n",
       "3        Nogales     Arizona       2604  US-Mexico Border 2019-03-01   \n",
       "4    Trout River    New York        715  US-Canada Border 2019-03-01   \n",
       "\n",
       "                       Measure  Value  Latitutde  Longitude Month_year  Year  \\\n",
       "0                       Trucks  34447 -115.48433   32.67524    2019-03  2019   \n",
       "1         Rail Containers Full    428  -67.94271   47.16207    2019-03  2019   \n",
       "2                       Trucks  81217 -117.05333   32.57333    2019-03  2019   \n",
       "3                       Trains     62 -110.93361   31.34028    2019-03  2019   \n",
       "4  Personal Vehicle Passengers  16377  -73.44253   44.99001    2019-03  2019   \n",
       "\n",
       "   Month  \n",
       "0      3  \n",
       "1      3  \n",
       "2      3  \n",
       "3      3  \n",
       "4      3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Month_year'] = test['Date'].dt.to_period('M')\n",
    "test['Year'] = test[\"Date\"].dt.year\n",
    "test['Month'] = test[\"Date\"].dt.month\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116ea12bc88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, (ax1, ax2) = plt.subplots(nrows=2, ncols=1)\n",
    "figure.set_size_inches(18, 8)\n",
    "sns.barplot(data=train, x=\"Year\", y=\"Value\", ax=ax1)\n",
    "sns.barplot(data=train, x=\"Month\", y=\"Value\", ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116ea2b29c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, (ax3, ax4) = plt.subplots(nrows=2, ncols=1)\n",
    "figure.set_size_inches(18, 8)\n",
    "sns.pointplot(data=train, x=\"Year\", y=\"Value\", hue=\"Border\", ax=ax3)\n",
    "sns.pointplot(data=train, x=\"Month\", y=\"Value\", hue=\"Border\", ax=ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116ea65a048>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>log_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512</td>\n",
       "      <td>6.240276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Value  log_value\n",
       "0      0   0.000000\n",
       "1      0   0.000000\n",
       "2      0   0.000000\n",
       "3      0   0.000000\n",
       "4    512   6.240276"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train[\"log_value\"] = np.log(train[\"Value\"] + 1)\n",
    "train[[\"Value\", \"log_value\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116ed213488>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "figure.set_size_inches(18, 4)\n",
    "sns.distplot(train[\"Value\"], ax=ax1)\n",
    "sns.distplot(train[\"log_value\"], ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>log_value</th>\n",
       "      <th>Value(recover)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512</td>\n",
       "      <td>6.240276</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Value  log_value  Value(recover)\n",
       "0      0   0.000000             0.0\n",
       "1      0   0.000000             0.0\n",
       "2      0   0.000000             0.0\n",
       "3      0   0.000000             0.0\n",
       "4    512   6.240276           512.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Value(recover)\"] = np.exp(train[\"log_value\"]) - 1\n",
    "train[[\"Value\", \"log_value\", \"Value(recover)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = [\"Port Name\", \"State\", \"Border\", \"Year\", \"Month\"]\n",
    "label_name = \"log_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263701, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Border</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walhalla</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metaline Falls</td>\n",
       "      <td>Washington</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oroville</td>\n",
       "      <td>Washington</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanceboro</td>\n",
       "      <td>Maine</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noonan</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Port Name         State            Border  Year  Month\n",
       "0        Walhalla  North Dakota  US-Canada Border  2012     12\n",
       "1  Metaline Falls    Washington  US-Canada Border  2012     12\n",
       "2        Oroville    Washington  US-Canada Border  2012     12\n",
       "3       Vanceboro         Maine  US-Canada Border  2012     12\n",
       "4          Noonan  North Dakota  US-Canada Border  2012     12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[factor]\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83033, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Border</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calexico East</td>\n",
       "      <td>California</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Van Buren</td>\n",
       "      <td>Maine</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otay Mesa</td>\n",
       "      <td>California</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nogales</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US-Mexico Border</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trout River</td>\n",
       "      <td>New York</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Port Name       State            Border  Year  Month\n",
       "0  Calexico East  California  US-Mexico Border  2019      3\n",
       "1      Van Buren       Maine  US-Canada Border  2019      3\n",
       "2      Otay Mesa  California  US-Mexico Border  2019      3\n",
       "3        Nogales     Arizona  US-Mexico Border  2019      3\n",
       "4    Trout River    New York  US-Canada Border  2019      3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test[factor]\n",
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263701,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.000000\n",
       "3    0.000000\n",
       "4    6.240276\n",
       "Name: log_value, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train[label_name]\n",
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(rmse)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def rmse(predict, actual):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    distance = predict - actual\n",
    "    square_distance = distance ** 2\n",
    "    mean_square_distance = square_distance.mean()\n",
    "    score = np.sqrt(mean_square_distance)\n",
    "    return score\n",
    "rmse_score = make_scorer(rmse)\n",
    "rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Layla_Jeon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: DataFrame.dtypes for data must be int, float or bool.\n",
      "                Did not expect the data types in fields Port Name, State, Border\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 200, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 400, max_depth = 100, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 50, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 75, learning_rate = 0.000100, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 1.000000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.100000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.010000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 0.750000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.001000, subsample = 1.000000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 0.700000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.500000, colsample_bylevel = 1.000000, colsample_bytree = 1.000000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.400000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 0.700000, Score = nan\n",
      "n_estimators = 2000, max_depth = 100, learning_rate = 0.000100, subsample = 0.750000, colsample_bylevel = 0.400000, colsample_bytree = 1.000000, Score = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-f91b7bab2549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                                  seed=37)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrmse_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         hyperparameters = {\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "n_estimators_list = [100, 300, 1000]\n",
    "\n",
    "max_depth_list = [50, 75, 100]\n",
    "learning_rate_list = [1.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "subsample_list = [0.5, 0.75, 1.0]\n",
    "colsample_bytree_list = [0.4, 0.7, 1.0]\n",
    "colsample_bylevel_list = [0.4, 0.7, 1.0]\n",
    "hyperparameters_list = []\n",
    "\n",
    "for n_estimators in n_estimators_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "            for subsample in subsample_list:\n",
    "                for colsample_bylevel in colsample_bylevel_list:\n",
    "                    for colsample_bytree in colsample_bytree_list:\n",
    "                        model = xgb.XGBRegressor(n_estimators=n_estimators,\n",
    "                                                 max_depth=max_depth,\n",
    "                                                 learning_rate=learning_rate,\n",
    "                                                 subsample=subsample,\n",
    "                                                 colsample_bytree=colsample_bytree,\n",
    "                                                 colsample_bylevel=colsample_bylevel,\n",
    "                                                 seed=37)\n",
    "\n",
    "                        score = cross_val_score(model, X_train, y_train, cv=20, scoring=rmse_score).mean()\n",
    "\n",
    "                        hyperparameters = {\n",
    "                            'score': score,\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_depth': max_depth,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'subsample': subsample,\n",
    "                            'colsample_bylevel': colsample_bylevel,\n",
    "                            'colsample_bytree': colsample_bytree,\n",
    "                        }\n",
    "\n",
    "                        hyperparameters_list.append(hyperparameters)\n",
    "                        print(f\"n_estimators = {n_estimators}, max_depth = {max_depth:2}, learning_rate = {learning_rate:.6f}, subsample = {subsample:.6f}, colsample_bylevel = {colsample_bylevel:.6f}, colsample_bytree = {colsample_bytree:.6f}, Score = {score:.5f}\")\n",
    "\n",
    "hyperparameters_list = pd.DataFrame.from_dict(hyperparameters_list)\n",
    "hyperparameters_list = hyperparameters_list.sort_values(by=\"score\")\n",
    "print(hyperparameters_list.shape)\n",
    "hyperparameters_list.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
